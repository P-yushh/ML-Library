# -*- coding: utf-8 -*-
"""KNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1swBsjI8Kh0wUQSTbp8Zb_WhY4XFNsOCA
"""

from collections import Counter
class KNN():
    
    def __init__(self, k = 3):
        self.k = k
        self.Y_train = 0
        self.X_train = 0
        self.X_test = 0
        self.predict_label = []
    
    def data_split(self, X, Y, test_size = 0.2, cross_validation_size = 0.0, random_state = 1):
        row, col = X.shape

        # Shuffling the Input data!

        np.random.seed(random_state)
        np.random.shuffle(X)
        np.random.seed(random_state)
        np.random.shuffle(Y)
                
        # Splitting X data!

        test_len = int(row * test_size)
        cross_validation_len = int(row * cross_validation_size)
        temp = np.random.choice(row, test_len, replace = False)
        xtest = X[temp,:]
        X = np.delete(X, (temp), axis = 0)
        temp2 = np.random.choice(row, cross_validation_len, replace = False)
        xvalidation = X[temp2,:]
        X = np.delete(X, (temp2), axis = 0)
        xtrain = X

        # Splitting Y data!

        ytest = Y[temp]
        Y = np.delete(Y, (temp), axis = 0)
        yvalidation = Y[temp2]
        Y = np.delete(Y, (temp2), axis = 0)
        ytrain = Y
        
        # If user wants cross validation then return it, else don't!

        if cross_validation_size == 0:
            return xtrain, xtest, ytrain, ytest
        else:
            return xtrain, xtest, xvalidation, ytrain, ytest, yvalidation    

    def calculate_distance(self, x1, x2):
        return np.sqrt(np.sum((x1 - x2)**2))
    
    def predict(self, Xtest, Xtrain, Ytrain):
        if self.k == 0:
            raise ValueError("Value of 'k' cannot be 0! Enter a non-zero value or use default value")
        else:
            self.X_train = Xtrain
            self.Y_train = Ytrain
            self.X_test = Xtest
            self.predict_label = np.zeros(len(Ytrain))

            # Predicting labels of samples one by one!

            self.predict_label = [(self.predict_individual(i)) for i in self.X_test]
            return self.predict_label
        
    def predict_individual(self, X_test):
        distances = [self.calculate_distance(X_test, i) for i in self.X_train]
        sorted_indices = np.argsort(distances)[:self.k]
        k_labels = [self.Y_train[i] for i in sorted_indices]

        # Counting and then returning the class with the most occurence among the neighbors!

        most_common_class = Counter(k_labels).most_common()
        return most_common_class[0][0]
    
    def accuracy(self, Y_test):
        sum = 0
        for i in range(len(self.predict_label)):
            if self.predict_label[i] == Y_test[i]:
                sum += 1
        return print("The accuracy of prediction is : ",(sum/len(self.predict_label))*100)

import numpy as np
import pandas as pd
import matplotlib as plt
train_data=pd.read_csv("sample_data/mnist_train_small.csv", header = None)
test_data = pd.read_csv("sample_data/mnist_test.csv", header = None)
train_data.head(10)
X_train = train_data.values[:,1:]
Y_train = train_data.values[:,0]
X_test = test_data.values[:,1:]
Y_test = test_data.values[:,0]
knn = KNN()
pre = knn.predict(X_test, X_train, Y_train)
knn.accuracy(Y_test)