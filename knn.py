# -*- coding: utf-8 -*-
"""KNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1swBsjI8Kh0wUQSTbp8Zb_WhY4XFNsOCA
"""
import numpy as np
import pandas as pd
import matplotlib as plt
from collections import Counter
class KNN():
    
    def __init__(self, k = 3):
        self.k = k
        self.Y_train = 0
        self.X_train = 0
        self.X_test = 0
        self.predict_label = []
    
    def data_split(self, X, Y, test_size = 0.2, cross_validation_size = 0.0, random_state = 1):
        row, col = X.shape

        # Shuffling the Input data!

        np.random.seed(random_state)
        np.random.shuffle(X)
        np.random.seed(random_state)
        np.random.shuffle(Y)
                
        # Splitting X data!

        test_len = int(row * test_size)
        cross_validation_len = int(row * cross_validation_size)
        temp = np.random.choice(row, test_len, replace = False)
        xtest = X[temp,:]
        X = np.delete(X, (temp), axis = 0)
        temp2 = np.random.choice(row, cross_validation_len, replace = False)
        xvalidation = X[temp2,:]
        X = np.delete(X, (temp2), axis = 0)
        xtrain = X

        # Splitting Y data!

        ytest = Y[temp]
        Y = np.delete(Y, (temp), axis = 0)
        yvalidation = Y[temp2]
        Y = np.delete(Y, (temp2), axis = 0)
        ytrain = Y
        
        # If user wants cross validation then return it, else don't!

        if cross_validation_size == 0:
            return xtrain, xtest, ytrain, ytest
        else:
            return xtrain, xtest, xvalidation, ytrain, ytest, yvalidation    

    def calculate_distance(self, x1, x2):
        return np.sqrt(np.sum((x1 - x2)**2))
    
    def predict(self, Xtest, Xtrain, Ytrain):
        ''' This method determines the nearest class of the given sample according to the neighboring datapoints!
               It takes in the sample point, neighboring datapoints, and their labels as parameters respectively!'''
        if self.k == 0:
            raise ValueError("Value of 'k' cannot be 0! Enter a non-zero value or use default value")
        else:
            self.X_train = Xtrain
            self.Y_train = Ytrain
            self.X_test = Xtest
            self.predict_label = np.zeros(len(Ytrain))

            # Predicting labels of samples one by one!

            self.predict_label = [(self.predict_individual(i)) for i in self.X_test]
            return self.predict_label
        
    def predict_individual(self, X_test):
        distances = [self.calculate_distance(X_test, i) for i in self.X_train]
        sorted_indices = np.argsort(distances)[:self.k]
        k_labels = [self.Y_train[i] for i in sorted_indices]

        # Counting and then returning the class with the most occurence among the neighbors!

        most_common_class = Counter(k_labels).most_common()
        return most_common_class[0][0]
    
    def accuracy(self, Y_test):
        sum = 0
        for i in range(len(self.predict_label)):
            if self.predict_label[i] == Y_test[i]:
                sum += 1
        return print("The accuracy of prediction is : ",(sum/len(self.predict_label))*100)
